# **Projeto: C√°lculo de M√©tricas de Avalia√ß√£o de Aprendizado em Machine Learning**

## **üìñ Sobre o Projeto**

Este reposit√≥rio cont√©m o estudo e a implementa√ß√£o pr√°tica do **C√°lculo de M√©tricas de Avalia√ß√£o de Aprendizado**, um tema fundamental na √°rea de Machine Learning. O objetivo deste projeto √© demonstrar como avaliar quantitativamente o desempenho de um modelo de classifica√ß√£o.

O estudo te√≥rico e a implementa√ß√£o do c√≥digo est√£o consolidados no notebook:  
`Calculation_of_Learning_Evaluation_Metrics_Confusion_Matrix.ipynb`

## **üéØ O Tema: C√°lculo de M√©tricas de Avalia√ß√£o de Aprendizado**

Ap√≥s treinar um modelo de Machine Learning, como podemos saber se ele √© realmente eficaz? Apenas treinar n√£o √© suficiente; precisamos **validar** e **medir** seu desempenho de forma objetiva. √â aqui que entram as **m√©tricas de avalia√ß√£o**.

M√©tricas s√£o medidas quantific√°veis que nos permitem analisar o resultado de um modelo, ou seja, medir sua performance em uma tarefa espec√≠fica. Para modelos de classifica√ß√£o, a ferramenta central para essa an√°lise √© a **Matriz de Confus√£o**.

### **Matriz de Confus√£o**

A Matriz de Confus√£o √© uma tabela que visualiza o desempenho de um algoritmo, comparando as classes reais com as classes previstas pelo modelo[cite: 49]. Ela nos permite ver n√£o apenas quantos acertos e erros o modelo cometeu, mas tamb√©m os *tipos* de acertos e erros.

|                | **Classe Predita: Positiva** | **Classe Predita: Negativa** |
| :------------- | :--------------------------: | :--------------------------: |
| **Classe Real: Positiva** |       VP (Verdadeiro Positivo)       |        FN (Falso Negativo)       |
| **Classe Real: Negativa** |       FP (Falso Positivo)        |       VN (Verdadeiro Negativo)       |

* **VP (Verdadeiro Positivo):** Acerto. O modelo previu "Positivo" e o real era "Positivo".
* **VN (Verdadeiro Negativo):** Acerto. O modelo previu "Negativo" e o real era "Negativo".
* **FP (Falso Positivo):** Erro do Tipo I. O modelo previu "Positivo", mas o real era "Negativo".
* **FN (Falso Negativo):** Erro do Tipo II. O modelo previu "Negativo", mas o real era "Positivo".

A partir desses quatro valores, podemos calcular diversas m√©tricas para entender o comportamento do nosso modelo.

A partir desses quatro valores, podemos calcular diversas m√©tricas para entender o comportamento do nosso modelo.

### **Principais M√©tricas de Avalia√ß√£o**

As seguintes m√©tricas foram estudadas e implementadas no projeto:

#### **1\. Acur√°cia (Accuracy)**

Mede o percentual geral de acertos do modelo. √â a m√©trica mais simples, mas pode ser enganosa em datasets desbalanceados.

* **F√≥rmula:** `(VP \+ VN) / (VP \+ VN \+ FP \+ FN)`

#### **2\. Precis√£o (Precision)**

Dentre todas as vezes que o modelo previu a classe "Positiva", quantas ele realmente acertou? √â uma m√©trica importante quando o custo de um Falso Positivo √© alto.

* **F√≥rmula:** `VP / (VP \+ FP)`

#### **3\. Sensibilidade (Recall ou Revoca√ß√£o)**

Dentre todos os casos que eram realmente "Positivos", quantos o modelo conseguiu identificar? √â crucial quando o custo de um Falso Negativo √© alto.

* **F√≥rmula:** `VP / (VP \+ FN)`

#### **4\. Especificidade**

Dentre todos os casos que eram realmente "Negativos", quantos o modelo conseguiu identificar?

* **F√≥rmula:** `VN / (VN \+ FP)`

#### **5\. F1-Score**

√â a m√©dia harm√¥nica entre a Precis√£o e a Sensibilidade. √â uma √≥tima m√©trica para ter uma vis√£o balanceada do desempenho, especialmente quando as classes s√£o desiguais.

* **F√≥rmula:** `2 * [(Precis√£o * Sensibilidade) / (Precis√£o + Sensibilidade)]`

## **üíª Implementa√ß√£o Pr√°tica**

O estudo e a aplica√ß√£o pr√°tica de todos esses conceitos est√£o detalhados no notebook Jupyter `Calculation_of_Learning_Evaluation_Metrics_Confusion_Matrix.ipynb`.

No notebook, voc√™ encontrar√°:

* A simula√ß√£o de dados de um modelo de classifica√ß√£o.  
* A gera√ß√£o da Matriz de Confus√£o usando a biblioteca Scikit-learn.  
* A extra√ß√£o dos valores de VP, VN, FP e FN da matriz gerada.  
* O c√°lculo e a exibi√ß√£o de todas as m√©tricas de avalia√ß√£o discutidas acima.

## **‚öôÔ∏è Como Executar o Projeto**

1. Clone este reposit√≥rio.  
2. Abra o arquivo .ipynb no Google Colab, Jupyter Notebook ou qualquer ambiente compat√≠vel.  
3. Execute as c√©lulas em ordem para ver a gera√ß√£o da matriz de confus√£o e o c√°lculo das m√©tricas.

## üë®‚Äçüíª Author

<img 
  align=left 
  margin=10 
  width=80 
  src="https://avatars.githubusercontent.com/u/188269406"
/>
<p>&nbsp&nbsp&nbsp&nbspLuciano Grossi<br/><br/>
    &nbsp&nbsp&nbsp
    <a href="https://github.com/grossitech"><img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"></a>
    <a href="https://twitter.com/lucianogrossi"><img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white" alt="Twitter"></a>
    <a href="https://www.linkedin.com/in/lucianogrossi"><img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"></a>
</p>

---

## üìú License

This project is under the MIT License. See the [LICENSE](LICENSE) file for more details.